# ICPR 2024 Competition on Claim Span Identification

## Disclaimer
- The dataset may contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety
- The dataset may identify individuals (i.e., one or more natural persons), either directly or indirectly
- The dataset contain data that might be considered sensitive in any way (e.g., data that reveals race or ethnic origins, sexual orientations, religious beliefs, political opinions, etc.)


## Submission format
Participating teams are expected to submit the following in a zipped file named `<team_name>.zip` by the submission deadline:

- A folder called `preds/` containing one or two (max) prediction file(s) for each track in which the team is participating. These files should be named as `en_0.json`, `en_1.json`, `hi_0.json`, `hi_1.json`, `ml_0.json`, `ml_1.json` respectively for the three tracks given in the [competition website](https://sites.google.com/view/icpr24-csi/evaluation). You may only submit any subset of files among these (the names have to be exactly same).
Exact format for the test predictions files is described below.

- Codes for (i) training the model, and (ii) generating predictions on the test set using the model. Detailed instructions for running the code should be given in a README file.

- One report (doc / PDF of 1-2 pages) describing all the models, highlighting any novel steps taken to improve the models, hyperparameters / settings for reproducibility (e.g., batch size, learning rate), etc.


## Input Data Format
The English and Hindi sets of the data have **(1500 samples)** each, and the Multilingual file is a combination of these two. These splits are stored in standard JSON files. You may open the `.json` files in any text editor to visualise the data structure. 

Note that the usernames have been anonimyzed by giving them unique IDs.

On loading the data file (say with `json.load()` in python), it will return a list of dictionaries, one for each of the data points. Each dictionary has an ***"index"*** key (0, 1, 2, ...) and the ***"text_tokens"*** . 
The *"text_tokens"* contain a list of tokens that when joined form the text input. 

*Note that the output vectors (described below) for each data point need to be of the same size as the "text_tokens" list*


## Output Predictions Format
The output predictions file should again be a `.json` file, containing a list of lists, one list for each of the data points. The ordering of the internal lists should be the same as the corresponding data point in the original test file!
Each of the internal lists should also be the same size as the corresponding *"text_tokens"* (**0/1** for each of the tokens). The elements marked **1** denote that the corresponding token is part of a claim-span, and **0** denotes it is *NOT* part of any claim. 

For example, consider two texts -- 
- *"I  read  that  mrna  vaccines  cause  cancer  !"* 
- *"I  will  never  take  a  covid  vaccine  . . ."* 

Assume that your model thinks the first example contains a claim with the claim-span *"mrna  vaccines  cause  cancer"* while the second example does not contain a claim. Then the output JSON-file should look like:
```
[
    [0 0 0 1 1 1 1 0], 
    [0 0 0 0 0 0 0 0 0 0]
]
```

*Note that the number of tokens generated by a model's tokenizer may not be equal to the actual number of text tokens. You may need to convert the predicted vectors so that the final output vectors are the same size as text_tokens.*

***Note that the prediction file needs to be in the exact same format or they will not processed by the automated checker and will be disqualified.***


## More Queries
For any further clarification, please write to [csi.icpr2024@gmail.com](mailto:csi.icpr2024@gmail.com)